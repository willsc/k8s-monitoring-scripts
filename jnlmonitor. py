#!/usr/bin/env python

import paramiko
import csv
import os
import argparse

# Read the hostnames from a configuration file
def read_hosts_config(config_file):
    with open(config_file, 'r') as file:
        hosts = [line.strip() for line in file if line.strip()]
    return hosts

# Check for all files with a pattern in the directory and all subdirectories
def get_all_matching_files_and_timestamps(host, directory, pattern, ssh_user, ssh_key):
    ssh = paramiko.SSHClient()
    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    try:
        ssh.connect(host, username=ssh_user, key_filename=ssh_key)

        # Recursively search for all files ending with the specified pattern
        command = f"find {directory} -type f -name '*{pattern}'"
        stdin, stdout, stderr = ssh.exec_command(command)
        matching_files = stdout.read().decode().strip().split('\n')

        results = []
        for file_path in matching_files:
            if file_path:  # Check if file_path is not empty
                # Get the timestamp for each file
                command = f"stat -c '%y' {file_path}"
                stdin, stdout, stderr = ssh.exec_command(command)
                full_timestamp = stdout.read().decode().strip()
                shortened_timestamp = full_timestamp.split()[0] + " " + full_timestamp.split()[1][0:5]  # Shorten timestamp to 'YYYY-MM-DD HH:MM'

                results.append((file_path, shortened_timestamp))
        ssh.close()
        return results

    except Exception as e:
        print(f"Error connecting to {host}: {e}")
        return []

# Write results to a CSV file (append mode)
def write_results_to_csv(results, output_file):
    with open(output_file, mode='a', newline='') as csvfile:
        fieldnames = ['Index', 'Host', 'Path', 'Status', 'Timestamp']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

        if os.stat(output_file).st_size == 0:
            writer.writeheader()  # Write headers only if the file does not exist

        index = 1  # Index for the current batch of results
        for host, file_path, timestamp in results:
            writer.writerow({
                'Index': index,
                'Host': host,
                'Path': file_path,
                'Status': '1',  # Status is always "1" because these are found files
                'Timestamp': timestamp
            })
            index += 1

# Main function
def main():
    parser = argparse.ArgumentParser(description="Search for files on remote hosts and log results.")
    parser.add_argument('--user', required=True, help='SSH username')
    parser.add_argument('--key', required=True, help='Path to the private SSH key file')
    parser.add_argument('--hosts', required=True, help='Path to the host configuration file')
    parser.add_argument('--pattern', required=True, help='File pattern to search for')

    args = parser.parse_args()

    ssh_user = args.user
    ssh_key = args.key
    config_file = args.hosts
    pattern = args.pattern
    directory = "/deploy/data/jnl"  # Directory to check
    output_file = "file_existence_results.csv"

    hosts = read_hosts_config(config_file)
    results = []

    for host in hosts:
        matching_files = get_all_matching_files_and_timestamps(host, directory, pattern, ssh_user, ssh_key)
        for file_path, timestamp in matching_files:
            results.append((host, file_path, timestamp))

    write_results_to_csv(results, output_file)
    print(f"Results appended to {output_file}")

if __name__ == "__main__":
    main()